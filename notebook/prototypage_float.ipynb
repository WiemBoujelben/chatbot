{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67f70f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\wiwi\\gi3\\qi\\projet\\chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 23 lines with encoding: latin-1\n",
      "Processing 23 documents...\n",
      "Processing 1/23: h: U B S bonjour...\n",
      "Processing 2/23: c: oui bonjour est-ce que je pourrais avoir monsie...\n",
      "Processing 3/23: h: c'est lui-même...\n",
      "Processing 4/23: c: ah bonjour j'essayais de vous appeler e j'ai eu...\n",
      "Processing 5/23: h: où ça...\n",
      "Processing 6/23: c: à l'accueil...\n",
      "Processing 7/23: h: oui...\n",
      "Processing 8/23: c: donc voilà et c'est parce que moi je e c'est po...\n",
      "Processing 9/23: h: ouais e...\n",
      "Processing 10/23: c: en première année...\n",
      "Processing 11/23: c: et e elle m'a donné un numéro de code...\n",
      "Processing 12/23: h: ouais...\n",
      "Processing 13/23: c: et quand je fais ce numéro de code on me dit co...\n",
      "Processing 14/23: h: e attendez attendez parce que là je suis pas à ...\n",
      "Processing 15/23: c: e oui 0 1 26 0 4...\n",
      "Processing 16/23: h: 0 1 26 0 4 ouais...\n",
      "Processing 17/23: c: et dans combien de temps...\n",
      "Processing 18/23: h: e ben dans deux minutes trois minutes là...\n",
      "Processing 19/23: c: deux minutes trois minutes...\n",
      "Processing 20/23: h: ouais...\n",
      "Processing 21/23: c: ok...\n",
      "Processing 22/23: h: allez au revoir madame...\n",
      "Processing 23/23: c: au revoir...\n",
      "✅ All embeddings saved successfully in FLOAT array table!\n",
      "\n",
      "Searching for: 'services bancaires'\n",
      "\n",
      "=== Using Cosine Similarity ===\n",
      "Resultats trouves (Cosine Similarity):\n",
      "ID: 6, Distance: 0.8420, Similarity: 0.1580\n",
      "Corpus: c: à l'accueil\n",
      "---\n",
      "ID: 14, Distance: 0.8624, Similarity: 0.1376\n",
      "Corpus: h: e attendez attendez parce que là je suis pas à mon bureau vous pouvez me rapeler au 0 2 97\n",
      "---\n",
      "ID: 1, Distance: 0.8669, Similarity: 0.1331\n",
      "Corpus: h: U B S bonjour\n",
      "---\n",
      "\n",
      "=== Using Euclidean Distance ===\n",
      "Resultats trouves (Euclidean Distance):\n",
      "ID: 6, Distance: 1.2977\n",
      "Corpus: c: à l'accueil\n",
      "---\n",
      "ID: 14, Distance: 1.3134\n",
      "Corpus: h: e attendez attendez parce que là je suis pas à mon bureau vous pouvez me rapeler au 0 2 97\n",
      "---\n",
      "ID: 1, Distance: 1.3168\n",
      "Corpus: h: U B S bonjour\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "import json\n",
    "\n",
    "conversation_file_path = \"..\\\\data\\\\022_00000017.txt\"\n",
    "\n",
    "# Load local embedding model (no API calls needed)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dimension = 384  # This model produces 384-dimensional vectors\n",
    "\n",
    "db_connection_str = \"dbname=postgres user=postgres password=root host=localhost port=5433\"\n",
    "\n",
    "def create_conversation_list(file_path: str):\n",
    "    encodings_to_try = ['utf-8', 'latin-1', 'iso-8859-1', 'cp1252', 'windows-1252']\n",
    "    \n",
    "    for encoding in encodings_to_try:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=encoding) as file:\n",
    "                text = file.read()\n",
    "                text_list = text.split(\"\\n\")\n",
    "                filtered_list = [chaine.strip() for chaine in text_list if chaine.strip() and not chaine.startswith(\"<\")]\n",
    "                print(f\"Successfully read {len(filtered_list)} lines with encoding: {encoding}\")\n",
    "                return filtered_list\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    \n",
    "    # Final attempt with error handling\n",
    "    with open(file_path, \"r\", encoding='utf-8', errors='ignore') as file:\n",
    "        text = file.read()\n",
    "        text_list = text.split(\"\\n\")\n",
    "        filtered_list = [chaine.strip() for chaine in text_list if chaine.strip() and not chaine.startswith(\"<\")]\n",
    "        print(f\"Read {len(filtered_list)} lines with error handling\")\n",
    "        return filtered_list\n",
    "\n",
    "def calculate_embeddings(corpus: str):\n",
    "    # Generate embeddings locally - no API calls!\n",
    "    embedding = model.encode(corpus).tolist()\n",
    "    return embedding\n",
    "\n",
    "def save_embedding(corpus: str, embedding: list, cursor):\n",
    "    # Store as FLOAT array instead of VECTOR\n",
    "    cursor.execute('INSERT INTO embeddings_float (corpus, embedding) VALUES (%s, %s)', (corpus, embedding))\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    import numpy as np\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def similar_corpus_float(input_corpus: str, db_connection_str: str, top_k: int = 3):\n",
    "    input_embedding = calculate_embeddings(input_corpus)\n",
    "    \n",
    "    conn = psycopg2.connect(db_connection_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get all embeddings from the database\n",
    "    cursor.execute(\"SELECT ID, corpus, embedding FROM embeddings_float\")\n",
    "    all_results = cursor.fetchall()\n",
    "    \n",
    "    # Calculate cosine similarity for each entry\n",
    "    similarities = []\n",
    "    for id, corpus, db_embedding in all_results:\n",
    "        # Calculate cosine similarity (higher = more similar)\n",
    "        similarity = cosine_similarity(input_embedding, db_embedding)\n",
    "        # Convert to distance (lower = more similar)\n",
    "        distance = 1 - similarity\n",
    "        similarities.append((id, corpus, db_embedding, distance))\n",
    "    \n",
    "    # Sort by distance (ascending)\n",
    "    similarities.sort(key=lambda x: x[3])\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return similarities[:top_k]\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    \"\"\"Calculate Euclidean distance between two vectors\"\"\"\n",
    "    import numpy as np\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "def similar_corpus_euclidean(input_corpus: str, db_connection_str: str, top_k: int = 3):\n",
    "    input_embedding = calculate_embeddings(input_corpus)\n",
    "    \n",
    "    conn = psycopg2.connect(db_connection_str)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get all embeddings from the database\n",
    "    cursor.execute(\"SELECT ID, corpus, embedding FROM embeddings_float\")\n",
    "    all_results = cursor.fetchall()\n",
    "    \n",
    "    # Calculate Euclidean distance for each entry\n",
    "    distances = []\n",
    "    for id, corpus, db_embedding in all_results:\n",
    "        distance = euclidean_distance(input_embedding, db_embedding)\n",
    "        distances.append((id, corpus, db_embedding, distance))\n",
    "    \n",
    "    # Sort by distance (ascending)\n",
    "    distances.sort(key=lambda x: x[3])\n",
    "    \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return distances[:top_k]\n",
    "\n",
    "try:\n",
    "    with psycopg2.connect(db_connection_str) as conn:\n",
    "        conn.autocommit = True\n",
    "        with conn.cursor() as cur:\n",
    "            # Create table with FLOAT array instead of VECTOR\n",
    "            cur.execute(\"DROP TABLE IF EXISTS embeddings_float\")\n",
    "            \n",
    "            cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS embeddings_float (\n",
    "                        ID SERIAL PRIMARY KEY, \n",
    "                        corpus TEXT,\n",
    "                        embedding FLOAT[]  -- Using FLOAT array instead of VECTOR\n",
    "                        )\"\"\")\n",
    "            \n",
    "            corpus_list = create_conversation_list(file_path=conversation_file_path)\n",
    "            \n",
    "            print(f\"Processing {len(corpus_list)} documents...\")\n",
    "            \n",
    "            for i, corpus in enumerate(corpus_list):\n",
    "                print(f\"Processing {i+1}/{len(corpus_list)}: {corpus[:50]}...\")\n",
    "                embedding = calculate_embeddings(corpus=corpus)\n",
    "                save_embedding(corpus=corpus, embedding=embedding, cursor=cur)\n",
    "            \n",
    "            conn.commit()\n",
    "            print(\"✅ All embeddings saved successfully in FLOAT array table!\")\n",
    "\n",
    "    # Test with different similarity methods\n",
    "    test_query = \"services bancaires\"\n",
    "    print(f\"\\nSearching for: '{test_query}'\")\n",
    "    \n",
    "    print(\"\\n=== Using Cosine Similarity ===\")\n",
    "    results_cosine = similar_corpus_float(test_query, db_connection_str, top_k=3)\n",
    "    \n",
    "    print(\"Resultats trouves (Cosine Similarity):\")\n",
    "    for id, corpus, embedding, distance in results_cosine:\n",
    "        similarity = 1 - distance  # Convert back to similarity score\n",
    "        print(f\"ID: {id}, Distance: {distance:.4f}, Similarity: {similarity:.4f}\")\n",
    "        print(f\"Corpus: {corpus}\")\n",
    "        print(\"---\")\n",
    "    \n",
    "    print(\"\\n=== Using Euclidean Distance ===\")\n",
    "    results_euclidean = similar_corpus_euclidean(test_query, db_connection_str, top_k=3)\n",
    "    \n",
    "    print(\"Resultats trouves (Euclidean Distance):\")\n",
    "    for id, corpus, embedding, distance in results_euclidean:\n",
    "        print(f\"ID: {id}, Distance: {distance:.4f}\")\n",
    "        print(f\"Corpus: {corpus}\")\n",
    "        print(\"---\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
